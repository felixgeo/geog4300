---
title: "Geog6300: Univariate regression"
output: html_notebook
editor_options: 
  chunk_output_type: console
---

```{r setup}
library(tidyverse)
library(sf)
library(tmap)
```


Here's our garden data from the class video lecture
```{r}
med.age<-c(43, 21, 25, 42, 56, 59)
garden<-c(99, 65, 79, 75, 87, 81)
data<-data.frame(cbind(med.age, garden))
```

Now we can create a linear model. The actual model doesn't tell you much, but a summary of it does.
```{r}
lm(garden~med.age, data=data) 
model<-lm(garden~med.age, data=data)
summary(model)
```

You can also plot this model. The abline function plots a regression line created by the model.
```{r}
plot(garden~med.age, data=data)
abline(model) 
```

Let's do a more complex model: pollen data. Does yearly mean temperature predict the levels of pollen from birch trees (Betula)? We will load the data and then make it spatial using the st_as_sf function in the sf package.

```{r}
Midwest_Pollen_Data<-read_csv("data/Midwest_Pollen_Data.csv")

pollen_data_sf<-st_as_sf(Midwest_Pollen_Data,coords=c(x="longitud",y="latitude"),crs=4326)
```

Let's look at the distribution of these variables first.
```{r}
hist(pollen_data_sf$Betula)
ggplot(pollen_data_sf,aes(sample=Betula))+
  stat_qq()+stat_qq_line()

hist(pollen_data_sf$tmeanyr)
ggplot(pollen_data_sf,aes(sample=tmeanyr))+
  stat_qq()+stat_qq_line()

ggplot(pollen_data_sf,aes(y=Betula,x=tmeanyr))+
  geom_point()
```

We can use tmap to visualize these points.

```{r}
tmap_mode("view")
tm_shape(pollen_data_sf) +
  tm_dots("Betula",size=.2)

tm_shape(pollen_data_sf) +
  tm_dots("tmeanyr",size=.2)
```

Now let's create a model.
```{r}
model<-lm(Betula~tmeanyr,data=pollen_data_sf)
summary(model)
```

We can plot out the model.
```{r}
plot(Betula~tmeanyr,data=pollen_data_sf)
abline(model)
```

##There's several diagnostics that can be used for regression.

R comes with some diagnostic plots baked in. To see them, just plot the model. There are four screens: 

1) The first is the values predicted by the model vs. the residuals. It shouldn't show a pattern.

2) The second is a QQ plot for residuals. These should appear normal.

3) The third should also appear random, it's similar to graph 1.

4) The last shows Cook's distance for outliers (See below). It identifies observations with the greatest "leverage" on the model by their row number. They will be near or past the dotted line thresholds.

```{r}
plot(model)
```

Here's a more detailed process for looking at model diagnostics:

*Normality of residuals: Plot/test the residuals. The "residuals" function pulls residuals from the model.
```{r}
pollen_data_sf$residuals<-residuals(model) #Pull the residuals from the model and add them to the dataset
ggplot(pollen_data_sf,aes(sample=residuals))+
  stat_qq()+stat_qq_line()
shapiro.test(pollen_data_sf$residuals)
```

Map the residuals using tmap
```{r}
tmap_mode("view")

tm_shape(pollen_data_sf) +
  tm_dots("residuals",size=.2)
```

*Heteroskedasticity: We can use the Breusch-Pagan test in the lmtest package. The null hypothesis is that the data is uniform, NOT heteroskedastic.
```{r}
library(lmtest)
bptest(model)
```

*Outliers: We'll use Cook's Distance to assess outliers This is adapted from: http://r-statistics.co/Outlier-Treatment-With-R.html See also https://onlinecourses.science.psu.edu/stat501/node/340 and http://www.statisticshowto.com/cooks-distance/.

In th example below, we plot the Cooke's distance for each observation, which shows the leverage it has in the model as a whole. We then add a cutoff line that shows values four times greater than the mean. Lastly, we add labels that give the row number of each identified outlier.

```{r}
cooks_dist<-data.frame(cooks=cooks.distance(model),x=1:nrow(pollen_data_sf))
cooks_mean<-mean(cooks_dist$cooks)

ggplot(cooks_dist,aes(x=x,y=cooks,label=x))+
  geom_point()+
  geom_text(hjust=-0.2, vjust=0)+
  geom_hline(yintercept=cooks_mean*4,col="red")
```

We can go even further. Let's join these distances back to the dataset. We can add a "dummy variable" called `outlier` using if_else. That dummy variable will be 1 if it falls above that 4x the mean threshhold for Cooks distance. This allows us to highlight just those observations above that cutoff.

```{r}
pollen_data_sf_cooks<-pollen_data_sf %>%
  bind_cols(cooks_dist) %>%
  mutate(outlier=if_else(cooks>cooks_mean*4,"1","0")) 
```

Where do those outliers fit in the overall distribution?

```{r}
ggplot(pollen_data_sf_cooks,aes(y=Betula,x=tmeanyr,color=outlier))+
  geom_point()
```

**Where** are these outliers? We can map it out.

```{r}
tm_shape(pollen_data_sf_cooks) +
  tm_dots("outlier",size=0.2)
```

Let's run a model without the outliers to see if anything significant changes.

```{r}
pollen_data_sf1<-pollen_data_sf_cooks %>%
  filter(outlier==0)
model_rev<-lm(Betula~tmeanyr,data=pollen_data_sf1)
summary(model_rev)

plot(Betula~tmeanyr,data=pollen_data_sf1)
abline(model_rev)
```

How does that new model compare to the old one? Look at the R2 for both as well as the size, direction, and significance of model coefficients. The `sjPlot` library allows us to print/compare these models side by side.

```{r}
summary(model)
summary(model_rev)

#install.packages("sjPlot")
library(sjPlot)
tab_model(model,model_rev)
```

How would you describe the difference between these models?

##You try it! 

Create a regression model for temperature and another tree species. Run model diagnostics to identify any issues in the model. Then summarise what you found.

```{r}

```

